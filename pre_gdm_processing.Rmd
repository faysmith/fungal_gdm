---
title: "R Notebook"
output: html_notebook
---

##Load required libraries
```{r}
library(phyloseq)
library(ggplot2)
library(dbplyr)
library(vegan)
library(scales)
library(reshape2)
library(dplyr)
library(grid)
library(MASS)
```

##Load the phyloseq object
Only select for the Kingdom Fungi for the phyloseq data
```{r}

ps <- readRDS("~/Documents/WWPS_soil_2018/output/WWP_Full_phyloseq_object.RDS")
ps = subset_taxa(ps, Kingdom == "k__Fungi")

#View the phyloseq object
ps
```

Everything looks good. We have a phyloseq object, which contains our OTU/taxonomic/sequence data, which has been combined with our soil metadata. The reason why we have 146 samples instead of 150 is that some of them only had a few seq counts, which ended up not being fungal (we think this happened somewhere between DNA amplification and seqencing)

#Start exploring the data
Explore the count and OTU distribution of the raw samples, before we normalize the data set. 

```{r}
readsumsdf = data.frame(nreads = sort(taxa_sums(ps), TRUE), sorted = 1:ntaxa(ps), 
    type = "OTUs")
readsumsdf = rbind(readsumsdf, data.frame(nreads = sort(sample_sums(ps), 
    TRUE), sorted = 1:nsamples(ps), type = "Samples"))
title = "Total number of reads"
p = ggplot(readsumsdf, aes(x = sorted, y = nreads)) + geom_bar(stat = "identity")
p + ggtitle(title) + scale_y_log10() + facet_wrap(~type, 1, scales = "free")

```
This looks pretty typical for an amplicon-based microbiome study. Thankfully, most samples have at least 100 reads. Regardless, we will use a technique to normalize the data to simulate an even "sequencing effort."


#Normalization by rarefying sample count
First, I'll remove the samples that have below 1000 counts. 
```{r}
#Can change the arbitrary cutoff read number
ps.sub = prune_samples(sample_sums(ps) > 1000, ps)
ps.sub
```

This leaves us with 94 samples that have more than 1,000 counts. Let's look at the distribution of the counts again:
```{r}
readsumsdf = data.frame(nreads = sort(taxa_sums(ps.sub), TRUE), sorted = 1:ntaxa(ps.sub), 
    type = "OTUs")
readsumsdf = rbind(readsumsdf, data.frame(nreads = sort(sample_sums(ps.sub), 
    TRUE), sorted = 1:nsamples(ps.sub), type = "Samples"))
title = "Total number of reads"
p = ggplot(readsumsdf, aes(x = sorted, y = nreads)) + geom_bar(stat = "identity")
p + ggtitle(title) + scale_y_log10() + facet_wrap(~type, 1, scales = "free")

```

Sample counts are more even now, but we still need to normalize the data by randomly sampling all libraries that have over 1000 counts. 
```{r}
ps.prune <- prune_samples(sample_sums(ps) > 1000, ps) 

#The set.seed function makes the randomization repeatable
set.seed(100)
ps.R <- rarefy_even_depth(ps.prune, sample.size = 1000)
```

Randomizing at this level has caused us to loose over 1,500 OTUs from our complete data set. This is a good place to introduce an alternative method for normalizing sample depth.

#Normalizing counts by using relative abundances
Traditionally, samples would be rarefied using random sub-sampling down to the lowest common sample size acceptable. However, there are issues with this approach (See https://www.frontiersin.org/articles/10.3389/fmicb.2017.02224/full#F2 and https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003531). Mixed models can be difficult to work with when developing diversity indexes as well. Thus, I will be using a simple transformation wich will change OTU counts into relative abundances, we can check both of these in the later analyses. 
```{r}
#In the following function, I use 100 as the sample count so it is comparable to our rarefied data set
ps.P <- transform_sample_counts(ps, function(x) 1000 * x / sum(x))
```

Let's now check both of our normalized data sets, to make sure the reads look the way they should.
```{r}
par(mfrow = c(1,2))
title = "Sum of reads for each sample, ps.P"
plot(sort(sample_sums(ps.P), TRUE), type = "h", main = title, ylab = "reads",
     ylim = c(0,1500))
```
Everything has been normalized the way we want it to. 

#Transform phyloseq data to make it compatable to downstream analyses
To continue, I need to make the phyloseq object compatable with a package named "vegan", which has many functions related to studying diversity and community structure. I'll use some codes from https://jacobrprice.github.io/2017/08/26/phyloseq-to-vegan-and-back.html for this. 

```{r}
# convert the sample_data() within a phyloseq object to a vegan (or GDM) compatible data object
pssd2veg <- function(physeq) {
  sd <- sample_data(physeq)
  return(as(sd,"data.frame"))
}

# convert the otu_table() within a phyloseq object to a vegan (or GDM) compatible data object
psotu2veg <- function(physeq) {
  OTU <- otu_table(physeq)
  if (taxa_are_rows(OTU)) {
    OTU <- t(OTU)
  }
  return(as(OTU, "matrix"))
}

ps.sd.veg <-  pssd2veg(ps.R)
ps.otu.veg <-  psotu2veg(ps.R)

#Create a reduced sample data file with no categorical variables
ps.sd.veg$SampleID = NULL
ps.sd.veg$cluster = NULL
ps.sd.veg$num = NULL
ps.sd.veg$topo = NULL
ps.sd.veg$Elevation = NULL
ps.sd.veg$Longitude = NULL
ps.sd.veg$Latitude = NULL

#Save reduced sample data file and the OTU file for later use (like GDM)
psv <- ps.sd.veg
write.csv(psv, "~/Documents/WWPS_soil_2018/fun_sd_gdm.csv")
write.csv(ps.otu.veg, "~/Documents/WWPS_soil_2018/fun_otu_gdm.csv")

```

Now I'm going to do the same with our relative abundance data.

```{r}
# convert the sample_data() within a phyloseq object to a vegan (or GDM) compatible data object
pssd2veg <- function(physeq) {
  sd <- sample_data(physeq)
  return(as(sd,"data.frame"))
}

# convert the otu_table() within a phyloseq object to a vegan (or GDM) compatible data object
psotu2veg <- function(physeq) {
  OTU <- otu_table(physeq)
  if (taxa_are_rows(OTU)) {
    OTU <- t(OTU)
  }
  return(as(OTU, "matrix"))
}

ps.sd.veg <-  pssd2veg(ps.P)
ps.otu.veg <-  psotu2veg(ps.P)

#Create a reduced sample data file with no categorical variables
ps.sd.veg$SampleID = NULL
ps.sd.veg$cluster = NULL
ps.sd.veg$num = NULL
ps.sd.veg$topo = NULL
ps.sd.veg$Elevation = NULL
ps.sd.veg$Longitude = NULL
ps.sd.veg$Latitude = NULL

#Save reduced sample data file and the OTU file for later use (like GDM)
psv <- ps.sd.veg
write.csv(psv, "~/Documents/WWPS_soil_2018/fun_sd_gdm_relab.csv")
write.csv(ps.otu.veg, "~/Documents/WWPS_soil_2018/fun_otu_gdm_relab.csv")

```
